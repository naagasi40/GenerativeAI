{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prabhu-Tejas/GenAIclimbers/blob/main/GenAiclimbers_v1_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e4b806-f470-4ea6-8607-468084b716ac",
      "metadata": {
        "id": "c6e4b806-f470-4ea6-8607-468084b716ac"
      },
      "source": [
        "This is the Generative AI Hackthon Project.\n",
        "\n",
        "Team name: GenAI Climbers\n",
        "\n",
        "\n",
        "Project name: Insurance:Expidating document validation processing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6wsceNXz-cu",
        "outputId": "2fe2aa73-9822-4387-aade-d03368f553e3"
      },
      "id": "h6wsceNXz-cu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.228-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.9 langchain-0.0.228 langchainplus-sdk-0.0.20 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR2ojp5J0P7B",
        "outputId": "81a26e7f-19ba-46f1-d5cc-4cf26c28c90a"
      },
      "id": "AR2ojp5J0P7B",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d703e22f-0b0b-4570-9c3e-bc0b2a983dba",
      "metadata": {
        "id": "d703e22f-0b0b-4570-9c3e-bc0b2a983dba"
      },
      "outputs": [],
      "source": [
        "#importing Libraries\n",
        "\n",
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROJECT_ID = \"gen-genaiclimbers\"  # @param {type:\"string\"}\n",
        "REGION = \"us-west1\"\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "ozJQZ3K66yYq"
      },
      "id": "ozJQZ3K66yYq"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nzENTnrQ6tMi"
      },
      "id": "nzENTnrQ6tMi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "vertex_llm_text = VertexAI(model_name=\"text-bison@001\")\n",
        "vertex_embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")"
      ],
      "metadata": {
        "id": "Y-y6I3u063Vf"
      },
      "id": "Y-y6I3u063Vf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b212268d-1f28-48ff-8782-ac450c894625",
      "metadata": {
        "id": "b212268d-1f28-48ff-8782-ac450c894625"
      },
      "outputs": [],
      "source": [
        "#data ingestion\n",
        "\n",
        "pdf_loader = PyPDFLoader('/content/ShahRukh_MedicalReport.pdf')\n",
        "pages = pdf_loader.load_and_split()\n",
        "print(pages[3].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f8aaf2-be3d-4d26-b954-e3ac5e94a03c",
      "metadata": {
        "id": "c7f8aaf2-be3d-4d26-b954-e3ac5e94a03c"
      },
      "outputs": [],
      "source": [
        "#Prompting\n",
        "\n",
        "question = \"Verify the hospital report, doctor report and the patient name and tell us whether the insurance claim can be approved?\"\n",
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the report is\n",
        "                    not sufficient in the context, say \"Claim is rejected\" \\n\\n\n",
        "                    Verify the doctor report \\n\n",
        "                    Verify the hospital report \\n\n",
        "                    Verify the names in doctor report , hospital report and verify the patient name\n",
        "                    and tell in precise way\\n\n",
        "                    and display the patient name and company name \\n\n",
        "                    will the cost claimed in the insurance policy \\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27fa44df-6d3b-4cf4-ab60-ecb6fd0bb54a",
      "metadata": {
        "id": "27fa44df-6d3b-4cf4-ab60-ecb6fd0bb54a"
      },
      "outputs": [],
      "source": [
        "# we are using Stuffing type of LLM chain\n",
        "\n",
        "stuff_chain = load_qa_chain(vertex_llm_text, chain_type=\"stuff\", prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0126507b-a2d1-46ea-bfd9-46cddab48006",
      "metadata": {
        "id": "0126507b-a2d1-46ea-bfd9-46cddab48006"
      },
      "source": [
        "Stuffing Chain\n",
        "\n",
        "The Stuffing chain serves as a solution for scenarios where the context length of the LLM is inadequate to handle extensive documents or a substantial amount of information. In such cases, a large document can be divided into smaller segments, and semantic search techniques can be employed to retrieve relevant documents based on the query. These retrieved documents are then “stuffed” into the LLM context, allowing for the generation of a response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af394bcf-5796-438c-a83c-7c46d8224169",
      "metadata": {
        "id": "af394bcf-5796-438c-a83c-7c46d8224169",
        "outputId": "6abf4640-0f46-4270-fb29-6aba0f4e92a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time of execution of above program is : 1249.807ms\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "start = datetime.now()\n",
        "stuff_answer = stuff_chain(\n",
        "    {\"input_documents\": pages[1:4], \"question\": question}, return_only_outputs=True\n",
        ")\n",
        "end = datetime.now()\n",
        "td = (end - start).total_seconds() * 10**3\n",
        "print(f\"The time of execution of above program is : {td:.03f}ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eec0458-aba3-4e1c-825f-f3614971f345",
      "metadata": {
        "id": "4eec0458-aba3-4e1c-825f-f3614971f345",
        "outputId": "39fa6a02-65cc-4625-e400-624712e0754e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'output_text': \"The insurance claim can be approved. The patient's name is \"\n",
            "                'Shah Rukh, and they are covered under the Capgemini group '\n",
            "                'insurance policy. The surgery is necessary to repair and '\n",
            "                \"stabilize the fractured bone in the patient's right hand. The \"\n",
            "                'estimated cost of the surgery is INR 1,10,000/-, and the '\n",
            "                'insurance policy covers this cost.'}\n"
          ]
        }
      ],
      "source": [
        "pprint(stuff_answer)"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-12.m109",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}